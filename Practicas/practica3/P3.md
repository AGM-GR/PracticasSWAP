# Práctica 3 SWAP

## Balanceo de carga con NGINX:

En nuestra máquina balanceadora de carga, instalamos el servidor nginx ejecutando la orden `sudo apt-get update && sudo apt-get install nginx`, tras instalarlo debemos configurarlo como balanceador de carga, para eso desactivamos su servicio web, editando en el fichero alojado en `/etc/nginx/nginx.conf`, comentamos la linea `# include /etc/nginx/sites-enabled/*.conf;`

Una vez hecho esto, editamos el archivo en `/etc/nginx/conf.d/default.conf` ya añadimos el siguiente contenido:

![ConfiguracionNginx](images/nginx_weight_conf.png?raw=true)

Como vemos en la imagen, a la primera máquina se le ha asignado un peso 2, por lo que recibirá el doble de peticiones que la máquina 2, porque la hemos considerado el doble de potente.

Tras esto reiniciamos el servicio de nginx con `sudo service nginx restart` y el balanceador estará listo.

El funcionamiento del balanceador, sin asignación de pesos, sería un reparto de las peticiones entre los servidores de forma equitativa mediante round-rovin por lo que las peticiones al balanceador quedarían de la siguiente forma:

![NginxRoundRovin](images/nginx_roundrovin.png?raw=true)

Y con nuestra configuración de peso 2 para la primera máquina las peticiones serian tal que así:

![NginxPesos](images/nginx_weights.png?raw=true)

## Balanceo de carga con Haproxy:

En nuestra máquina balanceadora de carga, instalamos el balanceador Haproxy ejecutando la orden `sudo apt-get update && sudo apt-get install haproxy`, tras instalarlo debemos configurarlo editando en el fichero alojado en `/etc/haproxy/haproxy.cfg` e introducir el siguiente contenido:

    global  
      daemon
      maxconn 256

    defaults
      mode http
      contimeout 4000
      clitimeout 42000
      srvtimeout 43000

    frontend http-in
      bind \*:80
      default_backend servers

    backend servers
      server m1 192.168.56.101:80 maxconn 32
      server m2 192.168.56.102:80 maxconn 32

Y lanzamos el servidor utilizando esta configuración con el comando: `sudo /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg`

Con haproxy, las peticiones se repartirán equitativamente con round-rovin entre las servidores definidos, tal y como hemos podido comprobar lanzando peticiones al balanceador:

![Haproxy](images/haproxy.png?raw=true)

## Comportamiento ante una alta carga de los balanceadores:

Para someter a nuestros servidores web a una alta carga, utilizaremos Apache Benchmark en nuestra máquina Host, sobre la máquina virtual balanceadora con el siguiente comando: `ab -n 1000 -c 10 http://192.168.56.103/index.html`

Con que lanzaremos hasta 1000 peticiones de 10 en 10 concurrentemente, los resultados han sido los siguientes con los dos tipos de balanceadores, primero nginx y luego haproxy:

![BenchmarkNginx](images/BenchmarkNginx.png?raw=true)

![BenchmarkHaproxy](images/BenchmarkHaproxy.png?raw=true)

Observamos que en general nginx ha sido más rápido en terminar el test, en tiempos de respuesta y más rapido en velocidad, además los valores minimos y máximos en los tiempos de conexión son más cercanos a la media que los valores de haproxy.
